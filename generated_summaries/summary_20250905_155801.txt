1. Key definitions and concepts
- Conditional probability: P(B|A) is the probability B occurs given A has occurred.
- Prior probability: initial probability before new information.
- Posterior probability: revised probability after incorporating new information.
- Likelihood: P(new data | hypothesis), used to update the prior.
- Joint probability: P(A ∩ B) is the probability both A and B occur.
- Law of total probability: expresses P(A) via a partition of sample space.

2. Fundamental formulas
- Conditional probability (definition)
  - P(B|A) = P(A ∩ B) / P(A)
- Symmetric expression for joint probability
  - P(A ∩ B) = P(A) P(B|A) = P(B) P(A|B)
- Bayes' theorem (basic two-event form)
  - P(B|A) = P(A|B) P(B) / P(A)
- Law of total probability (for a partition B1,...,Bn)
  - P(A) = sum_{i=1..n} P(A|Bi) P(Bi)
- Bayes' theorem (generalized for a partition B1,...,Bn)
  - P(Bj|A) = P(A|Bj) P(Bj) / [ sum_{i=1..n} P(A|Bi) P(Bi) ]

3. Important relationships and notes
- Prior → Likelihood → Posterior sequence:
  1 - Start with prior P(Bj)
  2 - Use likelihood P(A|Bj)
  3 - Compute posterior P(Bj|A) via Bayes' theorem
- Normalizing constant in Bayes' rule is P(A) given by the law of total probability.
- P(B|A) increases when P(A|B) is relatively large compared with P(A|other events) weighted by priors.
- Bayes can be applied with discrete counts or probabilities; both formulations are equivalent.

4. Intuitive (frequency/table) method
- Method:
  1 - Assume a convenient total N (e.g., 1000 or 100000).
  2 - Convert probabilities to counts: count(Bi) = N * P(Bi).
  3 - Compute cells: count(A ∩ Bi) = count(Bi) * P(A|Bi).
  4 - Use counts to compute desired conditional: P(Bj|A) = count(A ∩ Bj) / sum_i count(A ∩ Bi).
- Advantage: reduces algebra errors, makes denominators explicit.

5. Worked examples
- Example A: Orange County cigar smokers
  - Given:
    - P(male) = 0.51
    - P(female) = 0.49
    - P(cigar | male) = 0.095
    - P(cigar | female) = 0.017
  - Bayes calculation:
    - P(male | cigar) = P(cigar | male) P(male) / [P(cigar | male) P(male) + P(cigar | female) P(female)]
    - = (0.095 * 0.51) / (0.095 * 0.51 + 0.017 * 0.49)
    - ≈ 0.04845 / (0.04845 + 0.00833) ≈ 0.04845 / 0.05678 ≈ 0.853
  - Frequency/table check (N = 100,000):
    - males = 51,000; male cigar = 0.095*51,000 = 4,845
    - females = 49,000; female cigar = 0.017*49,000 = 833
    - total cigar = 4,845 + 833 = 5,678
    - P(male | cigar) = 4,845 / 5,678 ≈ 0.853

- Example B: ELT manufacturers and defectives
  - Given:
    - P(A) = 0.80, P(B) = 0.15, P(C) = 0.05
    - P(defective | A) = 0.04, P(defective | B) = 0.06, P(defective | C) = 0.09
  - Bayes calculation:
    - P(A | defective) = P(defective | A) P(A) / [ P(defective | A)P(A) + P(defective | B)P(B) + P(defective | C)P(C) ]
    - = (0.04 * 0.80) / (0.04*0.80 + 0.06*0.15 + 0.09*0.05)
    - = 0.032 / (0.032 + 0.009 + 0.0045) = 0.032 / 0.0455 ≈ 0.703
  - Frequency/table check (N = 10,000):
    - A total = 8,000; defective from A = 0.04*8,000 = 320
    - B total = 1,500; defective from B = 0.06*1,500 = 90
    - C total = 500; defective from C = 0.09*500 = 45
    - total defective = 320 + 90 + 45 = 455
    - P(A | defective) = 320 / 455 ≈ 0.703

6. Quick solution checklist (ordered steps)
1 - Identify hypothesis events B1,...,Bn and the observed event A.
2 - Record priors P(Bi) and likelihoods P(A|Bi).
3 - Compute P(A) = sum_i P(A|Bi) P(Bi).
4 - Compute posterior for target Bj: P(Bj|A) = P(A|Bj) P(Bj) / P(A).
5 - Optionally verify with frequency/table method using a convenient N.

7. Compact reference formulas (for quick revision)
- P(B|A) = P(A|B) P(B) / P(A)
- P(A) = sum_{i} P(A|Bi) P(Bi)
- P(A ∩ B) = P(A) P(B|A) = P(B) P(A|B)

End of summary.