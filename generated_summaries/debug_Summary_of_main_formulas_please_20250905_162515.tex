
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage[a4paper,margin=25mm]{geometry}
\usepackage{xcolor}
\definecolor{primary}{HTML}{0B6FA4}
\definecolor{secondary}{HTML}{3A6B8A}
\definecolor{accent}{HTML}{6E7B8C}
\definecolor{lightgray}{HTML}{F3F5F7}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tcolorbox}
\tcbuselibrary{skins,breakable}
\usepackage{sectsty}
\allsectionsfont{\color{primary}\sffamily}
\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries\sffamily\color{primary}}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries\sffamily\color{secondary}}{\thesubsection}{0.8em}{}
\titleformat{\subsubsection}{\normalsize\bfseries\sffamily\color{accent}}{\thesubsubsection}{0.6em}{}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.6pt}
\renewcommand{\footrulewidth}{0.4pt}
\renewcommand{\headrule}{\color{lightgray}\hrule height \headrulewidth \vspace{-\headrulewidth}}
\fancyhead[L]{\sffamily\small Course Notes Summary}
\fancyhead[C]{\sffamily\small Focus: Summary of main formulas please}
\fancyhead[R]{\sffamily\small Source: BayesTheorem.pdf}
\fancyfoot[L]{\sffamily\small Generated: 2025-09-05 16:25:15}
\fancyfoot[C]{}
\fancyfoot[R]{\sffamily\small \thepage}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=primary, urlcolor=secondary, citecolor=primary}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{2}
\raggedbottom
\usepackage{titling}
\pretitle{\begin{center}\vspace*{1cm}\sffamily}
\posttitle{\par\end{center}\vskip 0.2em}
\preauthor{}\postauthor{}
\predate{}\postdate{}
% Helper macros used by model output
\newcommand{\Prob}{\mathrm{P}}
\newcommand{\given}{\,\mid\,}

\begin{document}


\begin{titlepage}
  \thispagestyle{empty}
  \begin{center}
    \vspace*{1cm}
    \begin{center}
    \includegraphics[width=0.3\textwidth]{16.png}
    \end{center}
    \vspace{1em}
    {\sffamily\Huge\bfseries\color{primary} Course Notes Summary \par}
    \vspace{0.8em}
    {\sffamily\Large\color{secondary} Focus Area: Summary of main formulas please \par}
    \vspace{1.5em}
    \begin{tcolorbox}[enhanced,width=0.75\textwidth,colback=lightgray,colframe=primary,boxrule=0.8pt,sharp corners,left=6pt,right=6pt,top=6pt,bottom=6pt]\vspace{0.5em}
      \sffamily
      \begin{tabular}{@{}p{0.28\textwidth} p{0.62\textwidth}@{}}
        \textbf{Source: } & BayesTheorem.pdf \\
        \textbf{Generated:} & 2025-09-05 16:25:15 \\
        \textbf{Summary Type:} & Comprehensive \\
      \end{tabular}
    \end{tcolorbox}

    \vspace{1.5em}
    {\small\sffamily Prepared for quick revision and reference\par}
    \vfill

    {\small\sffamily \color{accent} Use this sheet as a step-by-step guide when solving problems.}
    \vspace{1.8cm}
  \end{center}
\end{titlepage}

\section{Key definitions}

\subsection{Conditional probability}
\begin{itemize}
\item $P(B\mid A) =$ probability that $B$ occurs given $A$ has occurred.
\item Formula: $P(B\mid A)=\dfrac{P(A\cap B)}{P(A)}$, provided $P(A)>0$.
\end{itemize}

\subsection{Prior, likelihood, posterior, evidence}
\begin{itemize}
\item Prior: $P(A) =$ initial probability of hypothesis $A$ before new data.
\item Likelihood: $P(B\mid A) =$ probability of observing data $B$ assuming $A$ is true.
\item Evidence (marginal): $P(B) =$ total probability of observing $B$.
\item Posterior: $P(A\mid B) =$ updated probability of hypothesis $A$ after observing $B$.
\end{itemize}

\subsection{Other useful facts}
\begin{itemize}
\item Multiplication rule: $P(A\cap B)=P(A)P(B\mid A)=P(B)P(A\mid B)$.
\item Independence: If $A$ and $B$ are independent, $P(A\cap B)=P(A)P(B)$ and $P(B\mid A)=P(B)$.
\end{itemize}

\section{Main formulas}

\subsection{Basic conditional probability}
$$
P(B\mid A)=\frac{P(A\cap B)}{P(A)}.
$$

\subsection{Bayes' theorem (two events / hypothesis)}
$$
P(A\mid B)=\frac{P(B\mid A)\,P(A)}{P(B)}.
$$

\subsection{Law of total probability (for partition \{A_1,A_2,\ldots,A_n\})}
$$
P(B)=\sum_{i} P(A_i)\,P(B\mid A_i).
$$
Use this as the denominator in Bayes' theorem when hypotheses form a partition.

\subsection{Generalized Bayes' theorem (n hypotheses $A_1,\ldots,A_n$)}
$$
P(A_k\mid B)=\frac{P(A_k)\,P(B\mid A_k)}{\sum_{i} P(A_i)\,P(B\mid A_i)}.
$$

\subsection{Frequency/count form (intuitive/table method)}
\begin{itemize}
\item Given counts, $P(A\mid B)=\dfrac{\#(A\cap B)}{\#(B)}$.
\item To use probabilities, assume total $N$ and compute cell counts:
$\#(A\cap B)=N\times P(A)\times P(B\mid A)$.
\end{itemize}

\subsection{Symmetry relation}
$$
P(A\mid B)\,P(B)=P(B\mid A)\,P(A).
$$

\section{Short worked examples}

\subsection{Cigar-smoking example (Orange County)}
\begin{enumerate}
\item Given: $P(\text{Male})=0.51$, $P(\text{Female})=0.49$.
\item Given: $P(\text{Cigar}\mid\text{Male})=0.095$, $P(\text{Cigar}\mid\text{Female})=0.017$.
\item Compute numerator: $P(\text{Male})P(\text{Cigar}\mid\text{Male})=0.51\times 0.095=0.04845$.
\item Compute denominator: $0.04845 + 0.49\times 0.017 = 0.04845 + 0.00833 = 0.05678$.
\item Posterior: $P(\text{Male}\mid\text{Cigar}) = \dfrac{0.04845}{0.05678}\approx 0.853$.
\end{enumerate}

\subsection{ELT (manufacturers) defective example}
\begin{enumerate}
\item Given priors: $P(A)=0.80$, $P(B)=0.15$, $P(C)=0.05$.
\item Given defect rates: $P(D\mid A)=0.04$, $P(D\mid B)=0.06$, $P(D\mid C)=0.09$.
\item Numerator for $A$: $0.80\times 0.04 = 0.032$.
\item Denominator: $0.032 + 0.15\times 0.06 + 0.05\times 0.09 = 0.032 + 0.009 + 0.0045 = 0.0455$.
\item Posterior: $P(A\mid D)=\dfrac{0.032}{0.0455}\approx 0.703$.
\end{enumerate}

\subsection{Table method (same cigar example with $N=100{,}000$)}
\begin{enumerate}
\item Compute counts: males $=51{,}000$, cigar-smoking males $=0.095\times 51{,}000=4{,}845$.
\item females $=49{,}000$, cigar-smoking females $=0.017\times 49{,}000=833$.
\item total cigar-smokers $=4{,}845+833=5{,}678$.
\item $P(\text{Male}\mid\text{Cigar})=4{,}845/5{,}678\approx 0.853$.
\end{enumerate}

\section{Important relationships \& connections}
\begin{itemize}
\item Posterior $\propto$ Prior $\times$ Likelihood: $P(A\mid B)\propto P(A)P(B\mid A)$. The denominator normalizes over all hypotheses.
\item Law of total probability supplies the evidence term required for normalization.
\item Bayes' theorem updates beliefs when new data arrives. Use priors that partition the sample space.
\item Frequency approach (assume an $N$) reduces algebra errors and aids intuition.
\item Independence simplifies many computations, but do not assume independence unless justified.
\end{itemize}

\section{Quick checklist for applying Bayes' theorem}
\begin{enumerate}
\item Identify hypotheses that partition the sample space: $\{A_1,\ldots,A_n\}$.
\item Obtain priors $P(A_i)$ for each hypothesis.
\item Obtain likelihoods $P(B\mid A_i)$ for observed data $B$.
\item Compute evidence $P(B)=\sum_i P(A_i)P(B\mid A_i)$.
\item Compute posterior for target hypothesis: $P(A_k\mid B)=\dfrac{P(A_k)P(B\mid A_k)}{P(B)}$.
\item Optionally verify with a contingency table using an assumed total $N$.
\end{enumerate}

\section{Common pitfalls}
\begin{itemize}
\item Forgetting to normalize (omitting $P(B)$).
\item Using a non-partitioned or incomplete set of hypotheses in the denominator.
\item Confusing $P(B\mid A)$ (likelihood) with $P(A\mid B)$ (posterior).
\item Applying independence incorrectly.
\end{itemize}

\section{One-line summaries}
\begin{itemize}
\item Bayes (two events): $P(A\mid B)=\dfrac{P(B\mid A)P(A)}{P(B)}$.
\item Generalized Bayes: $P(A_k\mid B)=\dfrac{P(A_k)P(B\mid A_k)}{\sum_i P(A_i)P(B\mid A_i)}$.
\item Frequency method: $P(A\mid B)=\dfrac{\#(A\cap B)}{\#(B)}$.
\end{itemize}

\end{document}
