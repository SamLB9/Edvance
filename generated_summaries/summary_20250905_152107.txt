Summary of Main Formulas — Bayes’ Theorem (study / revision sheet)

1. Key definitions
- Conditional probability: P(B | A) = probability that B occurs given A has occurred.
- Prior probability: initial probability of an event before new information is used (denote P(A)).
- Likelihood: P(new information | hypothesis) — e.g., P(B | A).
- Posterior probability: revised probability after using new information — e.g., P(A | B).
- Evidence (or marginal likelihood): overall probability of the new information, P(B).

2. Fundamental formulas
- Conditional probability (basic definition)
  P(B | A) = P(A ∩ B) / P(A), provided P(A) > 0.

- Multiplication rule (from conditional probability)
  P(A ∩ B) = P(A) P(B | A) = P(B) P(A | B).

- Independence (special case)
  A and B independent ⇔ P(B | A) = P(B) ⇔ P(A ∩ B) = P(A) P(B).

3. Bayes’ theorem — two-event form
- Bayes’ formula (general two-event)
  P(A | B) = [P(B | A) P(A)] / P(B).

- Using the complement Aᶜ (two-category partition)
  P(A | B) = [P(B | A) P(A)] / [P(B | A) P(A) + P(B | Aᶜ) P(Aᶜ)].

- Mnemonic form
  posterior ∝ prior × likelihood
  (then normalize by dividing by evidence P(B)).

4. Total probability theorem (needed for denominator / evidence)
- For a partition {A1, A2, …, An} of the sample space,
  P(B) = Σ_j P(B | A_j) P(A_j).
- For two events A and Aᶜ: P(B) = P(B | A)P(A) + P(B | Aᶜ)P(Aᶜ).

5. Bayes’ theorem — generalized (n events / partition)
- For events A1, A2, …, An forming a partition,
  P(A_i | B) = [P(A_i) P(B | A_i)] / Σ_{j=1..n} [P(A_j) P(B | A_j)].
- Each posterior P(A_i | B) is nonnegative and Σ_i P(A_i | B) = 1.

6. Intuitive (frequency/table) method — practical solving tip
- Pick a convenient total N (e.g., 1000, 10,000, 100,000).
- Convert each prior P(A_i) to counts: count(A_i) = N × P(A_i).
- Convert likelihoods to counts: count(A_i ∩ B) = count(A_i) × P(B | A_i).
- Sum counts of B across all Ai to get total count(B) = N × P(B).
- Posterior P(A_i | B) = count(A_i ∩ B) / count(B).
- This avoids algebra errors and gives intuitive contingency tables.

7. Step-by-step procedure for a Bayes problem
1. Identify hypotheses/partitions A1, A2, … (priors P(A_i)).
2. Identify observed evidence B and likelihoods P(B | A_i).
3. Compute evidence P(B) using total probability: Σ P(A_i) P(B | A_i).
4. Compute posterior(s): P(A_i | B) = [P(A_i) P(B | A_i)] / P(B).
5. Optionally, construct counts via an assumed N to check numerically.

8. Short worked examples (compact)

- Example A: Cigar-smoking / gender (from text)
  Given: P(Male)=0.51, P(Female)=0.49, P(Cigar | Male)=0.095, P(Cigar | Female)=0.017.
  Compute P(Male | Cigar):
  P(Cigar) = 0.51×0.095 + 0.49×0.017 = 0.04845 + 0.00833 = 0.05678.
  P(Male | Cigar) = (0.51×0.095) / 0.05678 ≈ 0.04845 / 0.05678 ≈ 0.853 (≈85.3%).

- Example B: ELT manufacturers and defective units (three-category)
  Given: P(A)=0.80, P(B)=0.15, P(C)=0.05; defect rates P(D | A)=0.04, P(D | B)=0.06, P(D | C)=0.09.
  P(D) = 0.80×0.04 + 0.15×0.06 + 0.05×0.09 = 0.032 + 0.009 + 0.0045 = 0.0455.
  P(A | D) = (0.80×0.04) / 0.0455 = 0.032 / 0.0455 ≈ 0.703 (≈70.3%).
  (Alternative counts: assume N=10,000 → defective counts: A:320, B:90, C:45 → posterior = 320/455 ≈ 0.703.)

9. Important relationships & checks
- Consistency: P(A ∩ B) computed either way must match: P(A)P(B | A) = P(B)P(A | B).
- Posterior normalization: Σ_i P(A_i | B) = 1 when {A_i} is a partition.
- Edge case (zero denominators): Bayes’ formula requires P(B) > 0.
- Independence test: if P(A | B) = P(A), then B gives no information about A.
- Beware base-rate fallacy: high likelihood P(B | A) alone does not imply high posterior P(A | B) — priors matter.

10. Common pitfalls and tips
- Always identify priors and likelihoods explicitly before algebra.
- Use the total-probability denominator — forgetting terms is the common error.
- Use frequency tables for intuition and arithmetic checks.
- Round only at the final step to avoid cumulative rounding errors.
- For small probabilities or many events, use precise arithmetic or software.

11. Quick formula cheat-sheet (memorize these)
- P(B | A) = P(A ∩ B) / P(A)
- P(A ∩ B) = P(A) P(B | A)
- P(B) = Σ_j P(B | A_j) P(A_j)
- P(A_i | B) = [P(A_i) P(B | A_i)] / Σ_j [P(A_j) P(B | A_j)]

Use this sheet to:
- Set up Bayes problems quickly (identify priors, likelihoods).
- Convert to counts for sanity checks.
- Remember posterior ∝ prior × likelihood and then normalize.

If you want, I can convert this into a one-page printable study card or produce a few more worked examples with contingency tables.