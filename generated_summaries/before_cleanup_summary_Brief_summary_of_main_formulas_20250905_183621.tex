\section{Key definitions and concepts}
\begin{itemize}
\item Conditional probability: $P(B\mid A)=\frac{P(A\text{ and }B)}{P(A)}$.
\item Prior probability: initial probability of an event before new information (e.g., $P(A)$).
\item Posterior probability: revised probability after new information (e.g., $P(A\mid B)$).
\item Joint (multiplication) rule: $P(A\text{ and }B)=P(A)P(B\mid A)=P(B)P(A\mid B)$.
\item Independence: $A$ and $B$ are independent iff $P(A\text{ and }B)=P(A)P(B)$ (equivalently $P(A\mid B)=P(A)$).
\end{itemize}

\section{Core formulas}
\begin{itemize}
\item Basic Bayes' theorem:
$$
P(A\mid B)=\frac{P(B\mid A)\,P(A)}{P(B)}.
$$
\item Conditional probability (alternative form using joint probability):
$$
P(B\mid A)=\frac{P(A\text{ and }B)}{P(A)}.
$$
\item Multiplication rule (useful to compute joint probabilities):
$$
P(A\text{ and }B)=P(A)\,P(B\mid A).
$$
\end{itemize}

\section{Law of total probability and generalized Bayes}
\begin{itemize}
\item Law of total probability (for partition $A_1,\dots,A_k$):
$$
P(B)=\sum_{i=1}^k P(A_i)\,P(B\mid A_i).
$$
\item Generalized Bayes (for event $A_k$ in a partition $A_1,\dots,A_k$):
$$
P(A_k\mid B)=\frac{P(A_k)\,P(B\mid A_k)}{\displaystyle\sum_{i=1}^k P(A_i)\,P(B\mid A_i)}.
$$
\item Use these when there are multiple mutually exclusive, exhaustive causes $A_i$ explaining $B$.
\end{itemize}

\section{Intuitive/table method (recommended practical procedure)}
\begin{enumerate}
\item Assume a convenient total population $N$ (e.g., $100$, $1{,}000$, or $100{,}000$).
\item Convert prior probabilities $P(A_i)$ to counts: $\text{count}(A_i)=N\cdot P(A_i)$.
\item For each $A_i$, compute $\text{count}(A_i\text{ and }B)=\text{count}(A_i)\cdot P(B\mid A_i)$.
\item Sum counts for $B$ over all $A_i$ to get total $\text{count}(B)$.
\item Compute desired posterior as
$$
P(A_k\mid B)=\frac{\text{count}(A_k\text{ and }B)}{\text{count}(B)},
$$
which is equivalent to Bayes' formula.
\end{enumerate}

\section{Worked examples (brief)}
\begin{itemize}
\item Example: Manufacturer / defect (three categories $A,B,C$).\\
Given: $P(A)=0.80,\;P(B)=0.15,\;P(C)=0.05$; $P(D\mid A)=0.04,\;P(D\mid B)=0.06,\;P(D\mid C)=0.09$.\\
Compute $P(A\mid D)$:
\[
\text{Numerator}=P(A)P(D\mid A)=0.80\times 0.04=0.032.
\]
\[
\text{Denominator}=0.032+0.15\times 0.06+0.05\times 0.09=0.032+0.009+0.0045=0.0455.
\]
\[
P(A\mid D)=\frac{0.032}{0.0455}\approx 0.703\quad(\text{same as }320/455).
\]

\item Example: Gender / cigar smoking.\\
Given: $P(\text{Male})=0.51,\;P(\text{Female})=0.49$; $P(\text{Cigar}\mid \text{Male})=0.095,\;P(\text{Cigar}\mid \text{Female})=0.017$.\\
Using $N=100{,}000$:
\[
\text{Males}=51{,}000\quad\Rightarrow\quad\text{male cigar}=51{,}000\times 0.095=4{,}845.
\]
\[
\text{Females}=49{,}000\quad\Rightarrow\quad\text{female cigar}=49{,}000\times 0.017=833.
\]
\[
\text{Total cigar}=4{,}845+833=5{,}678.
\]
\[
P(\text{Male}\mid \text{Cigar})=\frac{4{,}845}{5{,}678}\approx 0.853.
\]
\end{itemize}

\section{Important relationships and quick reminders}
\begin{itemize}
\item Bayes updates priors into posteriors using likelihoods $P(B\mid A_i)$.
\item Always verify the denominator ($P(B)$ or total $\text{count}(B)$) is $>0$.
\item Using counts (table method) reduces algebra errors and clarifies numerators/denominators.
\item For $k$ causes, compute all $P(A_i)P(B\mid A_i)$ and normalize the target term.
\item If events are independent, Bayes updating is trivial because $P(B\mid A_i)=P(B)$ for all $i$.
\end{itemize}

\section{Quick checklist for solving Bayes problems}
\begin{itemize}
\item Identify the partition $\{A_i\}$ and the observed event $B$.
\item Write priors $P(A_i)$ and likelihoods $P(B\mid A_i)$.
\item Compute $P(B)$ via the law of total probability.
\item Apply Bayes:
$$
P(A_k\mid B)=\frac{P(A_k)P(B\mid A_k)}{P(B)}
$$
or use the table method.
\end{itemize}