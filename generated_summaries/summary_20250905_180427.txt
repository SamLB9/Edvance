Definitions
- Prior probability: initial probability of an event before new information is observed.
- Posterior probability: revised probability of an event after new information is observed.
- Conditional probability: probability of event B given event A has occurred, written P(B|A).

Main formulas
- Conditional probability (basic):
  P(B|A) = P(A and B) / P(A)
- Bayes' theorem (two events):
  P(B|A) = P(A|B) P(B) / P(A)
- Total probability (two-event form):
  P(A) = P(A)P(A|B) + P(A)P(A|B^c)  (use appropriate partitioning; more generally below)
- Bayes' theorem (generalized, partition A1,...,An):
  P(Ak | B) = P(Ak) P(B | Ak) / [sum_{j=1..n} P(Aj) P(B | Aj)]
- Total probability (generalized):
  P(B) = sum_{j=1..n} P(Aj) P(B | Aj)

Intuitive/frequency formulation
- Replace probabilities by counts using an assumed total N.
- Compute cell counts: count(Aj and B) = N * P(Aj) * P(B | Aj).
- Then P(Ak | B) = count(Ak and B) / sum_j count(Aj and B).
- This produces the same numeric result as Bayes' formula and helps avoid substitution errors.

Examples
- ELT manufacturers (three events):
  Given:
  P(A) = 0.80, P(B) = 0.15, P(C) = 0.05
  P(D | A) = 0.04, P(D | B) = 0.06, P(D | C) = 0.09
  Compute P(A | D):
  P(A|D) = P(A) P(D|A) / [P(A)P(D|A) + P(B)P(D|B) + P(C)P(D|C)]
  = (0.80*0.04) / [0.80*0.04 + 0.15*0.06 + 0.05*0.09]
  = 0.032 / (0.032 + 0.009 + 0.0045) = 0.032 / 0.0455 ≈ 0.703
  Frequency check (N = 10,000): defective counts = 320 (A), 90 (B), 45 (C) total 455. P = 320/455 ≈ 0.703.

- Orange County cigar example:
  Given:
  P(male) = 0.51, P(female) = 0.49
  P(cigar | male) = 0.095, P(cigar | female) = 0.017
  Compute P(male | cigar):
  P(cigar) = 0.51*0.095 + 0.49*0.017 = 0.04845 + 0.00833 = 0.05678
  P(male | cigar) = 0.04845 / 0.05678 ≈ 0.853
  Frequency check (N = 100,000): male smokers = 4845, female smokers = 833, total smokers = 5678. P = 4845/5678 ≈ 0.853.

Application steps (how to use Bayes' theorem)
1 - Identify the hypothesis events A1,...,An that form a partition of the sample space.
2 - Determine prior probabilities P(Aj).
3 - Determine likelihoods P(B | Aj) for the observed evidence B.
4 - Compute P(B) via total probability: P(B) = sum_j P(Aj) P(B | Aj).
5 - Compute posterior: P(Ak | B) = P(Ak) P(B | Ak) / P(B).

Important relationships and connections
- Posterior ∝ Prior × Likelihood: P(Ak | B) ∝ P(Ak) P(B | Ak).
- Total probability provides the normalizing constant (denominator) for Bayes' theorem.
- The frequency-table (count) method is algebraically equivalent to the formula method but often easier to implement and check by inspection.
- Bayes' theorem is sequential: posteriors from one update can serve as priors for the next update when new evidence arrives.

Notes and pitfalls
- Ensure the Aj are a complete partition and P(B) > 0.
- Distinguish carefully between P(B|A) and P(A|B); they are generally not equal.
- Use the frequency/table method to reduce algebraic substitution errors.
- Round only at the final step to avoid cumulative rounding error.

Quick reference (compact formulas)
- P(B|A) = P(A and B) / P(A)
- P(B|A) = P(A|B) P(B) / P(A)
- P(B) = sum_j P(Aj) P(B | Aj)
- P(Ak | B) = P(Ak) P(B | Ak) / [sum_j P(Aj) P(B | Aj)]