
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage[a4paper,margin=25mm]{geometry}
\usepackage{xcolor}
\definecolor{primary}{HTML}{0B6FA4}
\definecolor{secondary}{HTML}{3A6B8A}
\definecolor{accent}{HTML}{6E7B8C}
\definecolor{lightgray}{HTML}{F3F5F7}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tcolorbox}
\tcbuselibrary{skins,breakable}
\usepackage{sectsty}
\allsectionsfont{\color{primary}\sffamily}
\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries\sffamily\color{primary}}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries\sffamily\color{secondary}}{\thesubsection}{0.8em}{}
\titleformat{\subsubsection}{\normalsize\bfseries\sffamily\color{accent}}{\thesubsubsection}{0.6em}{}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.6pt}
\renewcommand{\footrulewidth}{0.4pt}
\renewcommand{\headrule}{\color{lightgray}\hrule height \headrulewidth \vspace{-\headrulewidth}}
\fancyhead[L]{\sffamily\small Course Notes Summary}
\fancyhead[C]{\sffamily\small Focus: Brief summary of main formulas}
\fancyhead[R]{\sffamily\small Source: BayesTheorem.pdf}
\fancyfoot[L]{\sffamily\small Generated: 2025-09-05 18:01:01}
\fancyfoot[C]{}
\fancyfoot[R]{\sffamily\small \thepage}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=primary, urlcolor=secondary, citecolor=primary}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{2}
\raggedbottom
\usepackage{titling}
\pretitle{\begin{center}\vspace*{1cm}\sffamily}
\posttitle{\par\end{center}\vskip 0.2em}
\preauthor{}\postauthor{}
\predate{}\postdate{}
% Helper macros used by model output
\newcommand{\Prob}{\mathrm{P}}
\newcommand{\given}{\,\mid\,}

\begin{document}


\begin{titlepage}
  \thispagestyle{empty}
  \begin{center}
    \vspace*{1cm}
    \begin{center}
    \includegraphics[width=0.3\textwidth]{16.png}
    \end{center}
    \vspace{1em}
    {\sffamily\Huge\bfseries\color{primary} Course Notes Summary \par}
    \vspace{0.8em}
    {\sffamily\Large\color{secondary} Focus Area: Brief summary of main formulas \par}
    \vspace{1.5em}
    \begin{tcolorbox}[enhanced,width=0.75\textwidth,colback=lightgray,colframe=primary,boxrule=0.8pt,sharp corners,left=6pt,right=6pt,top=6pt,bottom=6pt]\vspace{0.5em}
      \sffamily
      \begin{tabular}{@{}p{0.28\textwidth} p{0.62\textwidth}@{}}
        \textbf{Source: } & BayesTheorem.pdf \\
        \textbf{Generated:} & 2025-09-05 18:01:01 \\
        \textbf{Summary Type:} & Comprehensive \\
      \end{tabular}
    \end{tcolorbox}

    \vspace{1.5em}
    {\small\sffamily Prepared for quick revision and reference\par}
    \vfill

    {\small\sffamily \color{accent} Use this sheet as a step-by-step guide when solving problems.}
    \vspace{1.8cm}
  \end{center}
\end{titlepage}

\section{Definitions}
\begin{itemize}
\item Conditional probability: $P(B\mid A)=\dfrac{P(A\cap B)}{P(A)}$. Probability that $B$ occurs given $A$ has occurred.
\item Prior probability: Initial probability of an event before new information is observed (e.g., $P(A)$).
\item Posterior probability: Revised probability after incorporating new information (e.g., $P(A\mid B)$).
\item Likelihood: $P(B\mid A)$, probability of observing the new information $B$ assuming $A$ is true.
\item Evidence (marginal probability): $P(B)$, total probability of observing $B$ across all scenarios.
\end{itemize}

\section{Main formulas}
\begin{itemize}
\item Conditional probability (basic)
  $$P(B\mid A)=\frac{P(A\cap B)}{P(A)}$$
  Equivalent relation:
  $$P(A\cap B)=P(A)\,P(B\mid A)=P(B)\,P(A\mid B).$$
\item Bayes' theorem (two events)
  $$P(A\mid B)=\frac{P(B\mid A)\,P(A)}{P(B)}.$$
\item Law of total probability (for partition $A_1,\dots,A_n$)
  $$P(B)=\sum_{i} P(A_i)\,P(B\mid A_i).$$
\item Bayes' theorem (generalized / $n$ events)
  $$P(A_j\mid B)=\frac{P(A_j)\,P(B\mid A_j)}{\sum_{i} P(A_i)\,P(B\mid A_i)}.$$
\item Relation useful for odds form\\
  Posterior odds $=$ Prior odds $\times$ Likelihood ratio:
  $$\frac{P(A\mid B)}{P(A^c\mid B)}=\frac{P(A)}{P(A^c)}\cdot\frac{P(B\mid A)}{P(B\mid A^c)}.$$
\end{itemize}

\section{Intuitive (table) method --- quick practical approach}
\begin{itemize}
\item Idea: Assume a convenient total population $N$ (e.g., $100{,}000$). Compute expected counts from probabilities and fill a contingency table.
\item Steps (ordered)
  \begin{enumerate}
  \item Choose $N$ (e.g., $100{,}000$).
  \item Compute counts for each $A_i$: $\text{count}(A_i)=N\times P(A_i)$.
  \item For each $A_i$, compute counts of $B$ and not-$B$: $\text{count}(A_i\cap B)=\text{count}(A_i)\times P(B\mid A_i)$.
  \item Sum counts across $A_i$ to get total $\text{count}(B)=\sum_i \text{count}(A_i\cap B)$.
  \item Compute posterior as $\dfrac{\text{count}(A_j\cap B)}{\text{count}(B)}=P(A_j\mid B)$.
  \end{enumerate}
\item Benefit: Reduces algebra mistakes; gives direct frequency interpretation.
\end{itemize}

\section{Application checklist --- how to apply Bayes correctly}
\begin{enumerate}
\item Identify mutually exclusive, exhaustive hypotheses $A_1,\dots,A_n$ and their priors $P(A_i)$.
\item Obtain likelihoods $P(B\mid A_i)$ for the observed evidence $B$.
\item Compute evidence $P(B)=\sum_i P(A_i)\,P(B\mid A_i)$.
\item Compute posterior $P(A_j\mid B)=\dfrac{P(A_j)\,P(B\mid A_j)}{P(B)}$.
\item Optionally convert to odds and use likelihood ratios for sequential updates.
\end{enumerate}

\section{Short examples (formulas and key numeric results)}
\begin{itemize}
\item ELT manufacturers (three-way example)\\
  Given: $P(A)=0.80$, $P(B)=0.15$, $P(C)=0.05$; $P(D\mid A)=0.04$, $P(D\mid B)=0.06$, $P(D\mid C)=0.09$.\\
  Evidence:
  $$P(D)=0.80\cdot 0.04+0.15\cdot 0.06+0.05\cdot 0.09=0.0455.$$
  Posterior:
  $$P(A\mid D)=\frac{0.80\cdot 0.04}{0.0455}\approx 0.703.$$
\item Cigar smoking (two-group example)\\
  Given: $P(\text{male})=0.51$, $P(\text{female})=0.49$; $P(\text{smoke}\mid\text{male})=0.095$, $P(\text{smoke}\mid\text{female})=0.017$.\\
  Evidence:
  $$P(\text{smoke})=0.51\cdot 0.095+0.49\cdot 0.017=0.05678.$$
  Posterior:
  $$P(\text{male}\mid\text{smoke})=\frac{0.51\cdot 0.095}{0.05678}\approx 0.854.$$
\end{itemize}

\section{Important relationships and notes}
\begin{itemize}
\item $P(A\mid B)\neq P(B\mid A)$ in general. Use Bayes' theorem to switch conditioning.
\item Bayes updates beliefs: prior $\to$ observe evidence (via likelihood) $\to$ posterior.
\item The law of total probability is essential for computing the denominator in Bayes' formula.
\item Use frequencies (table method) to avoid algebra errors and to interpret probabilities intuitively.
\item Bayes scales to many hypotheses; computation requires all priors and likelihoods for the partition.
\end{itemize}

\section{Quick reference summary (one-line formulas)}
\begin{itemize}
\item $P(B\mid A)=\dfrac{P(A\cap B)}{P(A)}$
\item $P(A\cap B)=P(A)\,P(B\mid A)$
\item $P(B)=\sum_i P(A_i)\,P(B\mid A_i)$
\item $P(A_j\mid B)=\dfrac{P(A_j)\,P(B\mid A_j)}{\sum_i P(A_i)\,P(B\mid A_i)}$
\end{itemize}

\end{document}
